import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression

from sklearn.metrics import accuracy_score, precision_score, f1_score, roc_auc_score, confusion_matrix

# 1️⃣ CARREGAMENTO DOS DADOS
file_path = "labelled_dysx.csv"
df = pd.read_csv(file_path)

# 2️⃣ ANÁLISE EXPLORATÓRIA (DADOS ORIGINAIS)

# 2.1 Matriz de Correlação
plt.figure(figsize=(10, 6))
sns.heatmap(df.corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Matriz de Correlação - Dados Originais")
plt.tight_layout()
plt.show()

# 2.2 Boxplots
# Selecione as variáveis de interesse (assumindo que elas estão nas colunas certas)
cols = ['Memory', 'Speed', 'Language_vocab', 'Visual_discrimination', 'Audio_Discrimination']
plt.figure(figsize=(12, 6))
sns.boxplot(data=df[cols])
plt.title("Boxplots das Variáveis - Dados Originais")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# 3️⃣ PRE-PROCESSAMENTO
# Transformar a variável alvo em binário: 1 se Label é 1 ou 2, 0 caso contrário
df['Label'] = df['Label'].apply(lambda x: 1 if x in [1, 2] else 0)

# Selecionar variáveis independentes e a variável alvo
X = df[cols]
y = df['Label']

# Divisão dos dados em treino (80%) e teste (20%), estratificando para manter a proporção das classes
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Normalização: ajustar os dados de treino e aplicar a transformação no teste
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Balanceamento (SMOTE) aplicado apenas no conjunto de treino
smote = SMOTE(random_state=42)
X_train_bal, y_train_bal = smote.fit_resample(X_train_scaled, y_train)

# 4️⃣ DEFINIÇÃO DOS MODELOS
models = {
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42),
    "SVM RBF": SVC(kernel='rbf', probability=True, random_state=42),
    "SVM Linear": SVC(kernel='linear', probability=True, random_state=42),
    "Logistic Regression": LogisticRegression(max_iter=1000, random_state=42)
}

# 5️⃣ TREINAMENTO, VALIDAÇÃO CRUZADA E AVALIAÇÃO
results = []
for name, model in models.items():
    # Treinar o modelo no conjunto balanceado
    model.fit(X_train_bal, y_train_bal)

    # Validação Cruzada (5 folds) no conjunto de treino balanceado
    cv_scores = cross_val_score(model, X_train_bal, y_train_bal, cv=5, scoring='accuracy')

    # Previsões no conjunto de teste (que não foi balanceado)
    y_pred = model.predict(X_test_scaled)

    # Se o modelo possui predict_proba, calcule ROC-AUC; caso contrário, defina como NaN.
    if hasattr(model, "predict_proba"):
        y_prob = model.predict_proba(X_test_scaled)[:, 1]
        roc_auc = roc_auc_score(y_test, y_prob)
    else:
        roc_auc = np.nan

    # Calcular as métricas
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')

    results.append({
        "Modelo": name,
        "Acurácia": accuracy,
        "Precisão": precision,
        "F1 Score": f1,
        "ROC-AUC": roc_auc,
        "CV Média": cv_scores.mean(),
        "CV Desvio": cv_scores.std()
    })

# Converter os resultados para DataFrame
result_df = pd.DataFrame(results)
print("Resultados dos Modelos:")
print(result_df)

# 6️⃣ Identificar o melhor modelo com base no F1 Score (por exemplo)
best_model_name = result_df.loc[result_df["F1 Score"].idxmax()]["Modelo"]
print("\nMelhor modelo baseado no F1 Score:", best_model_name)

# Obter o melhor modelo e calcular sua matriz de confusão
best_model = models[best_model_name]
y_pred_best = best_model.predict(X_test_scaled)
conf_matrix = confusion_matrix(y_test, y_pred_best)

# Plotar a matriz de confusão do melhor modelo
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap="Blues",
            xticklabels=["Sem Dislexia", "Com Dislexia"],
            yticklabels=["Sem Dislexia", "Com Dislexia"])
plt.xlabel("Previsto")
plt.ylabel("Real")
plt.title(f"Matriz de Confusão - {best_model_name}")
plt.tight_layout()
plt.show()
